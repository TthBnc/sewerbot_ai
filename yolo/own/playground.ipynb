{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.202 ðŸš€ Python-3.8.10 torch-1.14.0a0+44dac51c.nv23.02 CUDA:0 (Orin, 15389MiB)\n",
      "Setup complete âœ… (8 CPUs, 15.0 GB RAM, 99.1/116.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics as ultra\n",
    "ultra.checks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 780M/780M [00:19<00:00, 42.9MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
    "os.system('unzip -q tmp.zip -d datasets && rm tmp.zip ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "YOLOv8n summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov8n.yaml\")  # build a new model from scratch\n",
    "model = YOLO(\"yolov8n.pt\")  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Use the model\n",
    "model.train(data=\"coco128.yaml\", epochs=3)  # train the model\n",
    "# path = model.export(format=\"onnx\")  # export the model to ONNX format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m      \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mType:\u001b[0m           YOLO\n",
      "\u001b[0;31mString form:\u001b[0m   \n",
      "YOLO(\n",
      "           (model): DetectionModel(\n",
      "           (model): Sequential(\n",
      "           (0): Conv(\n",
      "           (conv): Conv2d <...> conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "           )\n",
      "           )\n",
      "           )\n",
      "           )\n",
      "           )\n",
      "\u001b[0;31mFile:\u001b[0m           ~/.local/lib/python3.8/site-packages/ultralytics/models/yolo/model.py\n",
      "\u001b[0;31mDocstring:\u001b[0m      YOLO (You Only Look Once) object detection model.\n",
      "\u001b[0;31mInit docstring:\u001b[0m\n",
      "Initializes the YOLO model.\n",
      "\n",
      "Args:\n",
      "    model (Union[str, Path], optional): Path or name of the model to load or create. Defaults to 'yolov8n.pt'.\n",
      "    task (Any, optional): Task type for the YOLO model. Defaults to None.\n",
      "\u001b[0;31mCall docstring:\u001b[0m Calls the 'predict' function with given arguments to perform object detection."
     ]
    }
   ],
   "source": [
    "model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 d:\\Programming\\Work\\sewerbot_ai\\yolo\\own\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    }
   ],
   "source": [
    "# returns a list of the predictions\n",
    "# single predict is still a list, but with a single index\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Results object with attributes:\n",
       "\n",
       "boxes: ultralytics.engine.results.Boxes object\n",
       "keypoints: None\n",
       "masks: None\n",
       "names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       "orig_img: array([[[122, 148, 172],\n",
       "        [120, 146, 170],\n",
       "        [125, 153, 177],\n",
       "        ...,\n",
       "        [157, 170, 184],\n",
       "        [158, 171, 185],\n",
       "        [158, 171, 185]],\n",
       "\n",
       "       [[127, 153, 177],\n",
       "        [124, 150, 174],\n",
       "        [127, 155, 179],\n",
       "        ...,\n",
       "        [158, 171, 185],\n",
       "        [159, 172, 186],\n",
       "        [159, 172, 186]],\n",
       "\n",
       "       [[128, 154, 178],\n",
       "        [126, 152, 176],\n",
       "        [126, 154, 178],\n",
       "        ...,\n",
       "        [158, 171, 185],\n",
       "        [158, 171, 185],\n",
       "        [158, 171, 185]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[185, 185, 191],\n",
       "        [182, 182, 188],\n",
       "        [179, 179, 185],\n",
       "        ...,\n",
       "        [114, 107, 112],\n",
       "        [115, 105, 111],\n",
       "        [116, 106, 112]],\n",
       "\n",
       "       [[157, 157, 163],\n",
       "        [180, 180, 186],\n",
       "        [185, 186, 190],\n",
       "        ...,\n",
       "        [107,  97, 103],\n",
       "        [102,  92,  98],\n",
       "        [108,  98, 104]],\n",
       "\n",
       "       [[112, 112, 118],\n",
       "        [160, 160, 166],\n",
       "        [169, 170, 174],\n",
       "        ...,\n",
       "        [ 99,  89,  95],\n",
       "        [ 96,  86,  92],\n",
       "        [102,  92,  98]]], dtype=uint8)\n",
       "orig_shape: (1080, 810)\n",
       "path: 'd:\\\\Programming\\\\Work\\\\sewerbot_ai\\\\yolo\\\\own\\\\bus.jpg'\n",
       "probs: None\n",
       "save_dir: None\n",
       "speed: {'preprocess': 2.001047134399414, 'inference': 11.999130249023438, 'postprocess': 2.9993057250976562}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0] # moves the results to cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 5.,  0.,  0.,  0., 11.,  0.], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes.cls # class names of the boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5., device='cuda:0')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].boxes.cls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number = results[0].boxes.cls[0].item()\n",
    "number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'person',\n",
       " 1: 'bicycle',\n",
       " 2: 'car',\n",
       " 3: 'motorcycle',\n",
       " 4: 'airplane',\n",
       " 5: 'bus',\n",
       " 6: 'train',\n",
       " 7: 'truck',\n",
       " 8: 'boat',\n",
       " 9: 'traffic light',\n",
       " 10: 'fire hydrant',\n",
       " 11: 'stop sign',\n",
       " 12: 'parking meter',\n",
       " 13: 'bench',\n",
       " 14: 'bird',\n",
       " 15: 'cat',\n",
       " 16: 'dog',\n",
       " 17: 'horse',\n",
       " 18: 'sheep',\n",
       " 19: 'cow',\n",
       " 20: 'elephant',\n",
       " 21: 'bear',\n",
       " 22: 'zebra',\n",
       " 23: 'giraffe',\n",
       " 24: 'backpack',\n",
       " 25: 'umbrella',\n",
       " 26: 'handbag',\n",
       " 27: 'tie',\n",
       " 28: 'suitcase',\n",
       " 29: 'frisbee',\n",
       " 30: 'skis',\n",
       " 31: 'snowboard',\n",
       " 32: 'sports ball',\n",
       " 33: 'kite',\n",
       " 34: 'baseball bat',\n",
       " 35: 'baseball glove',\n",
       " 36: 'skateboard',\n",
       " 37: 'surfboard',\n",
       " 38: 'tennis racket',\n",
       " 39: 'bottle',\n",
       " 40: 'wine glass',\n",
       " 41: 'cup',\n",
       " 42: 'fork',\n",
       " 43: 'knife',\n",
       " 44: 'spoon',\n",
       " 45: 'bowl',\n",
       " 46: 'banana',\n",
       " 47: 'apple',\n",
       " 48: 'sandwich',\n",
       " 49: 'orange',\n",
       " 50: 'broccoli',\n",
       " 51: 'carrot',\n",
       " 52: 'hot dog',\n",
       " 53: 'pizza',\n",
       " 54: 'donut',\n",
       " 55: 'cake',\n",
       " 56: 'chair',\n",
       " 57: 'couch',\n",
       " 58: 'potted plant',\n",
       " 59: 'bed',\n",
       " 60: 'dining table',\n",
       " 61: 'toilet',\n",
       " 62: 'tv',\n",
       " 63: 'laptop',\n",
       " 64: 'mouse',\n",
       " 65: 'remote',\n",
       " 66: 'keyboard',\n",
       " 67: 'cell phone',\n",
       " 68: 'microwave',\n",
       " 69: 'oven',\n",
       " 70: 'toaster',\n",
       " 71: 'sink',\n",
       " 72: 'refrigerator',\n",
       " 73: 'book',\n",
       " 74: 'clock',\n",
       " 75: 'vase',\n",
       " 76: 'scissors',\n",
       " 77: 'teddy bear',\n",
       " 78: 'hair drier',\n",
       " 79: 'toothbrush'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bus'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0].names[number]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 1 is not empty\n"
     ]
    }
   ],
   "source": [
    "if results[0].boxes.xyxy.numel() == 0: # igy tudjuk checkelni hogy talalt -e valamit\n",
    "    print(\"Tensor 1 is empty\")\n",
    "else:\n",
    "    print(\"Tensor 1 is not empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\Programming\\Work\\sewerbot_ai\\yolo\\playground.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Programming/Work/sewerbot_ai/yolo/playground.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m results[\u001b[39m3\u001b[39;49m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "results[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'xyxy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\Programming\\Work\\sewerbot_ai\\yolo\\playground.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Programming/Work/sewerbot_ai/yolo/playground.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m class_indices \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39;49mxyxy[\u001b[39m0\u001b[39m][:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mint\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/Work/sewerbot_ai/yolo/playground.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m confidences \u001b[39m=\u001b[39m results[\u001b[39m0\u001b[39m][:, \u001b[39m4\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Programming/Work/sewerbot_ai/yolo/playground.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m boxes \u001b[39m=\u001b[39m results[\u001b[39m0\u001b[39m][:, \u001b[39m.4\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'xyxy'"
     ]
    }
   ],
   "source": [
    "class_indices = results.xyxy[0][:, -1].to(int)\n",
    "confidences = results[0][:, 4]\n",
    "boxes = results[0][:, .4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mDocstring:\u001b[0m\n",
      "rectangle(img, pt1, pt2, color[, thickness[, lineType[, shift]]]) -> img\n",
      ".   @brief Draws a simple, thick, or filled up-right rectangle.\n",
      ".   \n",
      ".   The function cv::rectangle draws a rectangle outline or a filled rectangle whose two opposite corners\n",
      ".   are pt1 and pt2.\n",
      ".   \n",
      ".   @param img Image.\n",
      ".   @param pt1 Vertex of the rectangle.\n",
      ".   @param pt2 Vertex of the rectangle opposite to pt1 .\n",
      ".   @param color Rectangle color or brightness (grayscale image).\n",
      ".   @param thickness Thickness of lines that make up the rectangle. Negative values, like #FILLED,\n",
      ".   mean that the function has to draw a filled rectangle.\n",
      ".   @param lineType Type of the line. See #LineTypes\n",
      ".   @param shift Number of fractional bits in the point coordinates.\n",
      "\n",
      "\n",
      "\n",
      "rectangle(img, rec, color[, thickness[, lineType[, shift]]]) -> img\n",
      ".   @overload\n",
      ".   \n",
      ".   use `rec` parameter as alternative specification of the drawn rectangle: `r.tl() and\n",
      ".   r.br()-Point(1,1)` are opposite corners\n",
      "\u001b[1;31mType:\u001b[0m      builtin_function_or_method"
     ]
    }
   ],
   "source": [
    "cv2.rectangle?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Load the image\n",
    "image = cv2.imread('bus.jpg')\n",
    "\n",
    "# Assuming you have the bounding boxes as a tensor\n",
    "bounding_boxes = results[0].boxes.xyxy\n",
    "\n",
    "# Convert bounding boxes to a NumPy array for easier processing\n",
    "bounding_boxes = bounding_boxes.cpu().numpy()\n",
    "\n",
    "# Draw rectangles on the image\n",
    "for box in bounding_boxes:\n",
    "    x1, y1, x2, y2 = box  # Extract box coordinates\n",
    "    color = (0, 255, 0)  # BGR color for the rectangle (green in this case)\n",
    "    thickness = 2  # Thickness of the rectangle's border\n",
    "    image = cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), color, thickness)\n",
    "\n",
    "# Display the image with bounding boxes\n",
    "cv2.imshow('Image with Bounding Boxes', image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
